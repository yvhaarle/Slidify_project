names(trainSA)
modFit <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method='glm',family='binomial')
modFit <- train(factor(chd) ~ age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method='glm',family='binomial')
predictionT <- predict(modFit,trainSA)
prediction <- predict(modFit,testSA)
missClass(testSA$chd,as.numeric(prediction)-1)
missClass(trainSA$chd,as.numeric(predictionT)-1)
q()
TrainData <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"))
?url
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
temp <- tempfile()
download.file(url,temp,method="curl")
TrainData <- read.csv(temp)
unlink(temp)
names(TrainData)
TrainData$classe
names(TrainData)
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
temp <- tempfile()
download.file(url,temp,method="curl")
TrainData <- read.csv(temp)
unlink(temp)
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
temp <- tempfile()
download.file(url,temp,method="curl")
TestData <- read.csv(temp)
unlink(temp)
head(Train)
head(TrainData)
TrainData$max_roll_dumbbell
TestData$max_roll_dumbbell
head(TrainData)
TestData$stddev_roll_arm
TrainData$stddev_roll_arm
head(TrainData)
TrainData$new_window
head(TrainData)
q()
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
temp <- tempfile()
download.file(url,temp,method="curl")
TrainData <- read.csv(temp)
unlink(temp)
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
temp <- tempfile()
download.file(url,temp,method="curl")
TestData <- read.csv(temp)
unlink(temp)
library(dplyr)
library("dplyr")
TestDataPrep <- TestData[ , apply(TestData, 2, function(x) !any(is.na(x)))]
TestDataPrep
TrainDataPrep <- TrainData[ , apply(TrainData, 2, function(x) !any(is.na(x)))]
head(TrainDataPrep)
?select
head(TestDataPrep)
?mutate
?"dplyr"
?select
?arrange
?filter
apply(TrainData, 2, function(x) !any(is.na(x)))
apply(TrainData, 1, function(x) !any(is.na(x)))
apply(TrainData, 2, function(x) !any(is.na(x)))
test <- apply(TrainData, 2, function(x) !any(is.na(x)))
test
test[1,]
test[[,1]]
test[[]]
test[
]
names(test)
names(test[,1])
names(test[1,])
names(test[[1,]])
TestData
TestData(1)
TestData[1]
TestData[2]
TestData[,2]
test[,2]
typeof(test)
test
nam <- names(test)
nam
nam[test]
nam
nam[test]
TrainDataPrep <- select(TrainData,nam[test])
?select
TrainDataPrep <- select(TrainData,one_of(nam[test])
)
TrainDataPrep <- select(TrainData,one_of(nam[test]))
TrainDataPrep
head(TrainDataPrep)
TrainData$skewness_yaw_forearm
TrainData$skewness_yaw_forearm
TestData$skewness_yaw_forearm
apply(TrainData, 2, function(x) !any(x==""))
head(TrainDataPrep)
TrainDataPrep$kurtosis_roll_belt
test <- apply(TrainData, 2, function(x) !any(x==""))
test
test <- apply(TrainDataPrep, 2, function(x) !any(x==""))
test
varNoNA <- apply(TrainData, 2, function(x) !any(is.na(x)))
TrainDataPrep <- select(TrainData,nam[varNoNA])
varNoEmptyNoNA <- apply(TrainDataPrep, 2, function(x) !any(x==""))
TrainDataPrep <- select(TrainData,nam[varNoEmptyNoNA])
varNoNA <- apply(TrainData, 2, function(x) !any(is.na(x)))
TrainDataPrep <- select(TrainData,nam[varNoNA])
names[varNoNA]
varNoNA
names(varNoNA)
names(varNoNA[varNoNA])
varNoNA[varNoNA]
varNoNA[varNoNA]
names(TrainData[apply(TrainData, 2, function(x) !any(is.na(x)))  ])
\
names(TrainData[apply(TrainData, 2, function(x) !any(is.na(x)))  ])
names(TrainData[apply(TrainData, 2, function(x) !any(is.na(x)))])
varNoNA <- names(TrainData[apply(TrainData, 2, function(x) !any(is.na(x)))])
TrainDataPrep <- select(TrainData,one_of(varNoNA))
varNoEmptyNoNA <- names(TrainDataPrep[apply(TrainDataPrep, 2, function(x) !any(x==""))])
TrainDataPrep <- select(TrainData,one_of(varNoEmptyNoNA))
varNoNA <- names(TrainData[apply(TrainData, 2, function(x) !any(is.na(x)))])
TrainDataPrep <- select(TrainData,one_of(varNoNA))
varNoEmptyNoNA <- names(TrainDataPrep[apply(TrainDataPrep, 2, function(x) !any(x==""))])
TrainDataPrep <- select(TrainData,one_of(varNoEmptyNoNA))
varNoEmptyNoNA
head(TrainDataPrep)
notmeaningfull <- c("X","user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window","num_window")
TrainDataPrep <- select(TrainData,-notmeaningfull)
notmeaningfull <- c("X","user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window","num_window")
TrainDataPrep <- select(TrainData,-one_of(notmeaningfull))
TrainDataPrep
head(TrainDataPrep)
TrainDataPrep <- select(TrainDataPrep,-one_of(notmeaningfull))
head(TrainDataPrep)
varNoNA <- names(TrainData[apply(TrainData, 2, function(x) !any(is.na(x)))])
TrainDataPrep <- select(TrainData,one_of(varNoNA))
varNoEmptyNoNA <- names(TrainDataPrep[apply(TrainDataPrep, 2, function(x) !any(x==""))])
TrainDataPrep <- select(TrainData,one_of(varNoEmptyNoNA))
notmeaningfull <- c("X","user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window","num_window")
TrainDataPrep <- select(TrainDataPrep,-one_of(notmeaningfull))
head(TrainDataPrep)
q()
modFit <- train(classe ~ ., data = TrainDataPrep, method='rpart', prox= TRUE)
library('caret')
modFit <- train(classe ~ ., data = TrainDataPrep, method='rpart', prox= TRUE)
modFit <- train(classe ~ ., data = TrainDataPrep, method='rpart')
modFit
modFit$finalModel
library(rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
install.packages("ggplot2", "stringr", "munsell", "BradleyTerry2", "minqa", "nloptr")
install.packages("ggplot2", "stringr", "munsell", "BradleyTerry2",
"minqa", "nloptr")
install.packages("ggplot2", "stringr", "munsell", "BradleyTerry2",
"minqa", "nloptr")
install.packages("ggplot2", "stringr", "munsell", "BradleyTerry2", "minqa", "nloptr")
install.packages("ggplot2", "stringr", "munsell", "BradleyTerry2",
"minqa", "nloptr")
install.packages("ggplot2", "stringr", "munsell", "BradleyTerry2",
)
install.packages("rpart.plot")
library(rattle)
fancyRpartPlot(modFit$finalModel)
modFit <- train(classe ~ ., data = TrainDataPrep, method='gbm')
library(caret)
modFit <- train(classe ~ ., data = TrainDataPrep, method='gbm')
modFit <- train(classe ~ ., data = TrainDataPrep, method='tree')
modFit <- train(classe ~ ., data = TrainDataPrep, method='rpart')
?rpart.control()
modFit <- train(classe ~ ., data = TrainDataPrep, method='rpart')
modFit$finalModel
fancyRpartPlot(modFit$finalModel)
TrainDataPrep$classe
TrainDataPrep$classe == "D"
TrainDataPrep[TrainDataPrep$classe == "D"]
TrainDataPrep[,TrainDataPrep$classe == "D"]
TrainDataPrep$classe[TrainDataPrep$classe == "D"]
qplot(roll_arm,colour=classe, data=TrainDataPrep,geom='density')
qplot(roll_belt,colour=classe, data=TrainDataPrep,geom='density')
names(TrainDataPrep)
qplot(yaw_arm,colour=classe, data=TrainDataPrep,geom='density')
q()
library('caret')
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
## repeated three times
repeats = 3)
gbmFit1 <- train(classe ~ ., data = TrainDataPrep,
method = "gbm",
trControl = fitControl, verbose = TRUE)
bmFit1 <- train(classe ~ ., data = TrainDataPrep,
method = "gbm",
trControl = fitControl, verbose = FALSE)
set.seed(825)
library(doMC)
library('caret')
registerDoMC(cores = 4)
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
## repeated three times
repeats = 3)
set.seed(825)
gbmFit1 <- train(classe ~ ., data = TrainDataPrep,
method = "gbm",
trControl = fitControl, verbose = FALSE)
gbmFit1
gbmFit1$finalModel
gbmFit1$modelInfo
gbmFit1$results
gbmFit1$trainingData
gbmFit1$bestTune
gbmFit1$xlevels
gbmFit1$method
gbmFit1$modelType
gbmFit1$modelInfo
gbmFit1$results
gbmFit1$bestTune
gbmFit1$finalModel
gbmFit1$call
gbmFit1$pred
gbmFit1$dots
gbmFit1$control
gbmFit1$coefnames
gbmFit1$modelInfo
gbmFit1$finalModel$trees
gbmFit1$finalModel$c.splits
gbmFit1$finalModel$train.error
gbmFit1$finalModel$distribution
gbmFit1$finalModel$estimator
q()
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
temp <- tempfile()
download.file(url,temp,method="curl")
TrainData <- read.csv(temp)
unlink(temp)
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
temp <- tempfile()
download.file(url,temp,method="curl")
TestData <- read.csv(temp)
unlink(temp)
library("dplyr")
varNoNA <- names(TrainData[apply(TrainData, 2, function(x) !any(is.na(x)))])
TrainDataPrep <- select(TrainData,one_of(varNoNA))
varNoEmptyNoNA <- names(TrainDataPrep[apply(TrainDataPrep, 2, function(x) !any(x==""))])
TrainDataPrep <- select(TrainData,one_of(varNoEmptyNoNA))
notmeaningfull <- c("X","user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window","num_window")
TrainDataPrep <- select(TrainDataPrep,-one_of(notmeaningfull))
library(doMC)
library('caret')
registerDoMC(cores = 4)
#modFit <- train(classe ~ ., data = TrainDataPrep, method='gbm')
#   modFit <- train(classe ~ ., data = TrainDataPrep, method='rf', prox= TRUE)
#   ta
#  modfit
#run boosted tree with options from internet 5 nodes...
set.seed(825)
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
## repeated three times
repeats = 10)
gbmFit1 <- train(classe ~ ., data = TrainDataPrep,
method = "gbm",
trControl = fitControl, verbose = FALSE)
gbmFit1
predict(TestData,gbmFit1)
predict(TestData,gbmFit1$finalModel)
?predict
predict(gbmFit1,TestData)
TrainData$classe
predict(gbmFit1,TestData)
TestData
names(TestData)
head(TestData)
names(TestData)''
names(TestData)
TestData$problem_id
answers = predict(gbmFit1,TestData)
answers
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
qplot(roll_arm,colour=classe, data=TrainDataPrep,geom='density')
gbmFit1
gbmFit1$finalModel
gbmFit1$modelInfo
gbmFit1$results
gbmFit1
summary(gbmFit1)
gbmFit1
gbmFit1$finalModel
gbmFit1$pred
gbmFit1$control
gbmFit1$bestTune
gbmFit1$xlevels
gbmFit1$results
gbmFit1$results[-1]
gbmFit1$results[-1,-1]
gbmFit1$results[2]
gbmFit1$results[,2]
gbmFit1$results[2,]
gbmFit1$results[-1,]
gbmFit1$results[9,]
gbmFit1$results[9,]$Accuracy
gbmFit1$results[end,]$Accuracy
gbmFit1$results[-1,]$Accuracy
gbmFit1$results[-1,]
gbmFit1$results[2,]
tail(gbmFit1$results)
tail(gbmFit1$results,1)
tail(gbmFit1$results,1)$Accuracy
q()
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
ranfor <- train(y ~ ., data = vowel.train,method = "rf")
library('caret"')
library('caret")
)
""
''
''
library('caret')
ranfor <- train(y ~ ., data = vowel.train,method = "rf")
library(doMC)
library('caret')
registerDoMC(cores = 4)
gbmmodel <- train(y ~ ., data = vowel.train,method = "gbm")
predict(ranfor,vowel.test)
predict(ranfor,vowel.test)
predict(ranfor,vowel.test) == vowel.test$y
sum(predict(ranfor,vowel.test) == vowel.test$y)
sum(predict(ranfor,vowel.test) == vowel.test$y)/length(vowel.test$y)
sum(predict(gbmmodel,vowel.test) == vowel.test$y)/length(vowel.test$y)
sum(predict(gbmmodel,vowel.test) == predict(ranfor,vowel.test))/length(vowel.test$y)
test <- predict(gbmmodel,vowel.test) == predict(ranfor,vowel.test)
test
pred <- predict(gbmmodel,vowel.test)
pred(test)
pred(test)
pred
pred[test]
sum((predict(gbmmodel,vowel.test) == predict(ranfor,vowel.test))&&(predict(gbmmodel,vowel.test) == ranfor,vowel.test$y))/length(vowel.test$y)
sum((predict(gbmmodel,vowel.test) == predict(ranfor,vowel.test))&&(predict(gbmmodel,vowel.test) == vowel.test$y))/length(vowel.test$y)
sum((predict(gbmmodel,vowel.test) == predict(ranfor,vowel.test))&(predict(gbmmodel,vowel.test) == vowel.test$y))/length(vowel.test$y)
test = predict(gbmmodel,vowel.test) == predict(ranfor,vowel.test)
sum(test)
sum(test)/length(vowel.test$y)
test1 <- predict(gbmmodel,vowel.test) == pvowel.test$y
test1 <- predict(gbmmodel,vowel.test) == vowel.test$y
sum(test & test1)
sum(test & test1)/length(vowel.test$y)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rfmod <- train(diagnosis ~. , data=training,method = 'rf')
gbmmod <- train(diagnosis ~. , data=training,method = 'gbm')
ldamod <- train(diagnosis ~. , data=training,method = 'lda')
rfpred <- predict(rfmod,test)
test
rfpred <- predict(rfmod,testing)
gbmpred <- predict(gbmmod,testing)
ldapred <- predict(ldamod,testing)
predDF <- data.frame(rfpred,gbmpred,ldapred,diagnosis = testing$diagnosis)
combmodfit <- train(diagnosis ~ .,data=predDF,method='rf')
predDF
combpred <- predict(combmodfit,predDF)
sum(combpred == training$diagnosis)/length(training$diagnosis)
combpred
sum(combpred == training$diagnosis)/length(training$diagnosis)
sum(rfpred == training$diagnosis)/length(training$diagnosis)
sum(gbmpred == training$diagnosis)/length(training$diagnosis)
sum(ldapred == training$diagnosis)/length(training$diagnosis)
combmodfit <- train(diagnosis ~ .,data=predDF,method='gbm')
combpred <- predict(combmodfit,predDF)
sum(combpred == training$diagnosis)/length(training$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lassomod <- train()
lassomod <- train(CompressiveStrength ~. , data=training,method='lasso')
lassomod
plot.enet()
plot.enet(fit$finalModel, xvar = "penalty", use.color = TRUE)
plot.enet(lassmod$finalModel, xvar = "penalty", use.color = TRUE)
plot.enet(lassomod$finalModel, xvar = "penalty", use.color = TRUE)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
# Set the seed to 62433 and predict diagnosis with all the other variables using
# a random forest ("rf"), boosted trees ("gbm") and linear discriminant analysis
# ("lda") model. Stack the predictions together using random forests ("rf").
# What is the resulting accuracy on the test set? Is it better or worse than
# each of the individual predictions?
set.seed(62433)
# create models
fit1 <- train(diagnosis ~ ., data = training, method = "rf", trControl = trainControl(number = 4))
fit2 <- train(diagnosis ~ ., data = training, method = "gbm")
fit3 <- train(diagnosis ~ ., data = training, method = "lda")
# predict test
predict1 <- predict(fit1, newdata = testing)
predict2 <- predict(fit2, newdata = testing)
predict3 <- predict(fit3, newdata = testing)
# combine predictions
DF_combined <- data.frame(predict1, predict2, predict3, diagnosis = testing$diagnosis) # training$diagnosis?
fit_combined <- train(diagnosis ~ ., data = DF_combined, method = "rf")
predict4 <- predict(fit_combined, newdata = testing)
# confusion matrixes
c1 <- confusionMatrix(predict1, testing$diagnosis)
c2 <- confusionMatrix(predict2, testing$diagnosis)
c3 <- confusionMatrix(predict3, testing$diagnosis)
c4 <- confusionMatrix(predict4, testing$diagnosis)
print(paste(c1$overall[1], c2$overall[1], c3$overall[1], c4$overall[1]))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
# Set the seed to 325 and fit a support vector machine using the e1071 package
# to predict Compressive Strength using the default settings. Predict on the
# testing set. What is the RMSE?
set.seed(325)
library(e1071)
library(caret)
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
prediction <- predict(fit, testing)
accuracy(prediction, testing$CompressiveStrength)
prediction
prediction == testing$CompressiveStrength
library(forecast)
install.packages("forecast")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
# Set the seed to 325 and fit a support vector machine using the e1071 package
# to predict Compressive Strength using the default settings. Predict on the
# testing set. What is the RMSE?
set.seed(325)
library(e1071)
library(caret)
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
prediction <- predict(fit, testing)
accuracy(prediction, testing$CompressiveStrength)
library(forecast)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
# Set the seed to 325 and fit a support vector machine using the e1071 package
# to predict Compressive Strength using the default settings. Predict on the
# testing set. What is the RMSE?
set.seed(325)
library(e1071)
library(caret)
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
prediction <- predict(fit, testing)
accuracy(prediction, testing$CompressiveStrength)
q()
library(slidify)
setwd('/home/yvhaarle/Google Drive/Coursera/slidify_yvh/Predict_MPG/')
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
publish(user="yvhaarle",repo="Slidify_deck")
exit
exit
q()
